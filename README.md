# AlphaDog: A Gomoku AI Inspired by AlphaGo

## NOTE: This project has not finished yet.

## Overview

AlphaDog is a Gomoku (Five in a Row) AI inspired by the AlphaGo series. It uses a combination of deep neural networks and Monte Carlo Tree Search (MCTS) to play Gomoku, and is trained through Reinforcement Learning and self-play data.

AlphaDog 是一个受 AlphaGo 系列启发的五子棋 AI。它结合了深度神经网络和蒙特卡洛树搜索（MCTS），通过强化学习和自我对弈进行训练。

## Features

- **Deep Neural Network**: The AI uses a convolutional neural network (CNN) to evaluate board states and predict the best moves.
- **Monte Carlo Tree Search (MCTS)**: The MCTS algorithm is used to explore possible moves and improve decision-making.
- **Self-Play and Training**: The AI can generate self-play data and train its neural network to improve performance over time.

## Requirements

- numpy
- torch
- pygame
  and etc.

## Usage

- **Training**: To train the AI model, run the `_AlphaDog.py` script. You can adjust hyperparameters.
- **Playing**: To play against the AI, run the `WZQ_Pygame.py` script. You can try PvP/PvC/CvC.

- **训练**：运行 `_AlphaDog.py` 脚本来训练 AI 模型。你可以调整超参数。
- **对弈**：运行 `WZQ_Pygame.py` 脚本来与 AI 对弈。你可以选择PvP、PvC或者CvC。

## License

This project is licensed under the MIT License. 

## Acknowledgments

- Inspired by DeepMind's AlphaGo series.
- Some codes are generated by Deepseek.

---

Feel free to contribute, report issues, or suggest improvements!  
欢迎贡献代码、报告问题或提出改进建议！
